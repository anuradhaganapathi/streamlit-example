{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8544315-9f8a-450f-8b59-d6ef5848a9ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.8.1)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk) (1.4.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from nltk) (4.66.2)\n",
      "\u001b[33mWARNING: Error parsing requirements for fsspec: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/fsspec-2023.6.0.dist-info/METADATA'\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: s3fs in /opt/conda/lib/python3.10/site-packages (2024.3.1)\n",
      "Requirement already satisfied: aiobotocore<3.0.0,>=2.5.4 in /opt/conda/lib/python3.10/site-packages (from s3fs) (2.12.2)\n",
      "Collecting fsspec==2024.3.1 (from s3fs)\n",
      "  Using cached fsspec-2024.3.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.10/site-packages (from s3fs) (3.9.3)\n",
      "Requirement already satisfied: botocore<1.34.52,>=1.34.41 in /opt/conda/lib/python3.10/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs) (1.34.51)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.10.10 in /opt/conda/lib/python3.10/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs) (1.16.0)\n",
      "Requirement already satisfied: aioitertools<1.0.0,>=0.5.1 in /opt/conda/lib/python3.10/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs) (0.11.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (4.0.3)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from botocore<1.34.52,>=1.34.41->aiobotocore<3.0.0,>=2.5.4->s3fs) (1.0.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.10/site-packages (from botocore<1.34.52,>=1.34.41->aiobotocore<3.0.0,>=2.5.4->s3fs) (2.9.0)\n",
      "Requirement already satisfied: urllib3<2.1,>=1.25.4 in /opt/conda/lib/python3.10/site-packages (from botocore<1.34.52,>=1.34.41->aiobotocore<3.0.0,>=2.5.4->s3fs) (1.26.18)\n",
      "Requirement already satisfied: idna>=2.0 in /opt/conda/lib/python3.10/site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (3.6)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.34.52,>=1.34.41->aiobotocore<3.0.0,>=2.5.4->s3fs) (1.16.0)\n",
      "Using cached fsspec-2024.3.1-py3-none-any.whl (171 kB)\n",
      "\u001b[33mWARNING: Error parsing requirements for fsspec: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/fsspec-2023.6.0.dist-info/METADATA'\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: fsspec\n",
      "  Attempting uninstall: fsspec\n",
      "\u001b[33m    WARNING: No metadata found in /opt/conda/lib/python3.10/site-packages\u001b[0m\u001b[33m\n",
      "\u001b[0m    Found existing installation: fsspec 2023.6.0\n",
      "\u001b[31mERROR: Cannot uninstall fsspec 2023.6.0, RECORD file not found. You might be able to recover from this via: 'pip install --force-reinstall --no-deps fsspec==2023.6.0'.\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install nltk\n",
    "%pip install s3fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b82957d3-b55d-4194-83c8-703068dd0120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/sagemaker-\n",
      "[nltk_data]     user/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sagemaker, boto3, json\n",
    "from sagemaker import get_execution_role\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a1b24af-35f8-499b-980e-e2b5a6089ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://spam1/email_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "aws_role = get_execution_role()\n",
    "aws_region = boto3.Session().region_name\n",
    "sess = sagemaker.Session()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "# Specify S3 bucket and prefix where you have uploaded email_dataset.csv\n",
    "#training_data_bucket = \"spam1\"\n",
    "bucket = 'spam1'\n",
    "data_key = 'email_dataset.csv'\n",
    "data_location = 's3://{}/{}'.format(bucket, data_key)\n",
    "print(data_location)\n",
    "\n",
    "#training_dataset_s3_path = f\"s3://{training_data_bucket}/email_dataset.csv\"\n",
    "#print(training_dataset_s3_path)\n",
    "\n",
    "output_bucket = sess.default_bucket()\n",
    "output_prefix = \"\"\n",
    "\n",
    "s3_output_location = f\"s3://{output_bucket}/{output_prefix}/output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a891ff6-ff9d-4e61-8a7d-5818e7559bf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM</td>\n",
       "      <td>just wanted to check with you if you'll be sha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM</td>\n",
       "      <td>Hi,Job Title:- SAP ABAP Consultant Experience-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SPAM</td>\n",
       "      <td>Winter is here and so are the grand holidays</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM</td>\n",
       "      <td>Hi,We are looking for an expert in SAP for our...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM</td>\n",
       "      <td>Your prepaid recharge is now successful.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category                                            Message\n",
       "0      HAM  just wanted to check with you if you'll be sha...\n",
       "1      HAM  Hi,Job Title:- SAP ABAP Consultant Experience-...\n",
       "2     SPAM       Winter is here and so are the grand holidays\n",
       "3      HAM  Hi,We are looking for an expert in SAP for our...\n",
       "4      HAM           Your prepaid recharge is now successful."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "df = pd.read_csv(data_location)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5fb9d65-e566-4b62-8946-27cebf805191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Category\n",
       "HAM     42\n",
       "SPAM    38\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if dataset is balanced or not\n",
    "df['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "605607dc-8003-4c25-a016-f373661f53b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>__label__HAM</td>\n",
       "      <td>just wanted to check with you if you 'll be sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>__label__HAM</td>\n",
       "      <td>hijob title : - sap abap consultant experience...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>__label__SPAM</td>\n",
       "      <td>winter is here and so are the grand holidays</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>__label__HAM</td>\n",
       "      <td>hiwe are looking for an expert in sap for our ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>__label__HAM</td>\n",
       "      <td>your prepaid recharge is now successful .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Category                                            Message\n",
       "0   __label__HAM  just wanted to check with you if you 'll be sh...\n",
       "1   __label__HAM  hijob title : - sap abap consultant experience...\n",
       "2  __label__SPAM       winter is here and so are the grand holidays\n",
       "3   __label__HAM  hiwe are looking for an expert in sap for our ...\n",
       "4   __label__HAM          your prepaid recharge is now successful ."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize(message):\n",
    "    # delete quotation marks and commas , apply tokenization and join back into a string separating by spaces\n",
    "    return ' '.join([str(token) for token in nltk.word_tokenize(str(message).replace(',', '').replace('\"', '').lower())])\n",
    "    \n",
    "def prepare_data(df):\n",
    "    df['Category'] = df['Category'].map(lambda category : '__label__{}'.format(str(category).replace('__label__', '')))\n",
    "    df['Message'] = df['Message'].map(lambda message : tokenize(message)) \n",
    "    return df\n",
    "\n",
    "df_final = df[['Category', 'Message']].reset_index(drop=True)\n",
    "df_final = prepare_data(df_final)\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88c8f049-2df7-4ff5-8ffe-aa0e8997324f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "df_train, df_validation = train_test_split(df_final, \n",
    "                                           test_size=0.10,\n",
    "                                           stratify=df_final['Category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fa43bb1-3693-457f-8203-09f3e46b5924",
   "metadata": {},
   "outputs": [],
   "source": [
    "#upload transformed data to S3 bucket\n",
    "train_path = './train.csv'\n",
    "df_train[['Category', 'Message']].to_csv(train_path, index=False, header=False, sep=' ')\n",
    "\n",
    "validation_path = './validation.csv'\n",
    "df_validation[['Category', 'Message']].to_csv(validation_path, index=False, header=False, sep=' ')\n",
    "\n",
    "#Specify S3 bucket prefix\n",
    "train_s3_uri = sess.upload_data(bucket=bucket, key_prefix='trainig', path=train_path)\n",
    "validation_s3_uri = sess.upload_data(bucket=bucket, key_prefix='validation', path= validation_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64a05855-2305-4254-be33-0fd2347c7734",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    region=region,\n",
    "    framework='blazingtext'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95ca351c-f796-42bf-9a4c-192d2df597ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = sagemaker.estimator.Estimator(image_uri=image_uri, \n",
    "    role=aws_role, \n",
    "    instance_count=1, \n",
    "    instance_type='ml.m5.large',\n",
    "    volume_size=30,\n",
    "    max_run=7200,\n",
    "    disable_profiler=True,                                      \n",
    "    sagemaker_session=sess\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1292b895-3edc-45f4-b5ce-7f4ac9924220",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter\n",
    "estimator.set_hyperparameters(mode='supervised',   \n",
    "                              epochs=10,          \n",
    "                              learning_rate=0.01,  \n",
    "                              min_count=2,                          \n",
    "                              vector_dim=300,      \n",
    "                              word_ngrams=3)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f60e5be9-2850-4d30-860d-2151d456e0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = sagemaker.inputs.TrainingInput(\n",
    "    train_s3_uri, \n",
    "    distribution='FullyReplicated', \n",
    "    content_type='text/plain', \n",
    "    s3_data_type='S3Prefix'\n",
    ")\n",
    "validation_data = sagemaker.inputs.TrainingInput(\n",
    "    validation_s3_uri, \n",
    "    distribution='FullyReplicated', \n",
    "    content_type='text/plain', \n",
    "    s3_data_type='S3Prefix'\n",
    ")\n",
    "\n",
    "data_channels = {\n",
    "    'train': train_data,\n",
    "    'validation': validation_data \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43057e0b-9647-4e5f-9b20-414e1e806cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: blazingtext-2024-05-10-15-02-59-209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-10 15:02:59 Starting - Starting the training job...\n",
      "2024-05-10 15:03:15 Starting - Preparing the instances for training...\n",
      "2024-05-10 15:03:43 Downloading - Downloading input data...\n",
      "2024-05-10 15:04:23 Downloading - Downloading the training image...\n",
      "2024-05-10 15:04:39 Training - Training image download completed. Training in progress.\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[05/10/2024 15:04:43 WARNING 139733088479040] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34m[05/10/2024 15:04:43 WARNING 139733088479040] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34m/opt/amazon/python3.8/lib/python3.8/subprocess.py:848: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  self.stdout = io.open(c2pread, 'rb', bufsize)\u001b[0m\n",
      "\u001b[34m[05/10/2024 15:04:43 INFO 139733088479040] nvidia-smi took: 0.025179386138916016 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[05/10/2024 15:04:43 INFO 139733088479040] Running single machine CPU BlazingText training using supervised mode.\u001b[0m\n",
      "\u001b[34mNumber of CPU sockets found in instance is  1\u001b[0m\n",
      "\u001b[34m[05/10/2024 15:04:43 INFO 139733088479040] Processing /opt/ml/input/data/train/train.csv . File size: 0.0047054290771484375 MB\u001b[0m\n",
      "\u001b[34m[05/10/2024 15:04:43 INFO 139733088479040] Processing /opt/ml/input/data/validation/validation.csv . File size: 0.00043964385986328125 MB\u001b[0m\n",
      "\u001b[34mRead 0M words\u001b[0m\n",
      "\u001b[34mNumber of words:  118\u001b[0m\n",
      "\u001b[34m##### Alpha: -0.0001  Progress: 101.10%  Million Words/sec: 0.09 #####\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0000  Progress: 100.00%  Million Words/sec: 0.09 #####\u001b[0m\n",
      "\u001b[34mTraining finished.\u001b[0m\n",
      "\u001b[34mAverage throughput in Million words/sec: 0.09\u001b[0m\n",
      "\u001b[34mTotal training time in seconds: 0.10\u001b[0m\n",
      "\u001b[34m#train_accuracy: 0.9444\u001b[0m\n",
      "\u001b[34mNumber of train examples: 72\u001b[0m\n",
      "\u001b[34m#validation_accuracy: 0.625\u001b[0m\n",
      "\u001b[34mNumber of validation examples: 8\u001b[0m\n",
      "\n",
      "2024-05-10 15:05:09 Uploading - Uploading generated training model\n",
      "2024-05-10 15:06:50 Completed - Training job completed\n",
      "Training seconds: 187\n",
      "Billable seconds: 187\n"
     ]
    }
   ],
   "source": [
    "estimator.fit(\n",
    "    inputs=data_channels,\n",
    "    wait=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f357a82-a5a0-44c1-b25e-9008f013344b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.analytics:Warning: No metrics called train:mean_rho found\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>metric_name</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>train:accuracy</td>\n",
       "      <td>0.9444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>validation:accuracy</td>\n",
       "      <td>0.6250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp          metric_name   value\n",
       "0        0.0       train:accuracy  0.9444\n",
       "1        0.0  validation:accuracy  0.6250"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the accuracy of the train and validation dataset\n",
    "estimator.training_job_analytics.dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4e396f-7c74-43a9-9599-0ca154e9c495",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: blazingtext-2024-05-10-15-07-15-934\n",
      "INFO:sagemaker:Creating endpoint-config with name blazingtext-2024-05-10-15-07-15-934\n",
      "INFO:sagemaker:Creating endpoint with name blazingtext-2024-05-10-15-07-15-934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--"
     ]
    }
   ],
   "source": [
    "text_classifier = estimator.deploy(initial_instance_count=1,\n",
    "                                   instance_type='ml.m5.large',\n",
    "                                   serializer=sagemaker.serializers.JSONSerializer(),\n",
    "                                   deserializer=sagemaker.deserializers.JSONDeserializer())\n",
    "print()\n",
    "print('Endpoint name:  {}'.format(text_classifier.endpoint_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ccf6a6-311f-4fa5-acb2-3f6dd7665861",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "                # Spam\n",
    "                'Click on below link, provide your details and win this award' ,\n",
    "                'Best summer deal here',\n",
    "                #ham\n",
    "                'See you in the office on Friday.'\n",
    "\n",
    "]\n",
    "\n",
    "tokenized_message = [' '.join(nltk.word_tokenize(mesaage)) for mesaage in messages]\n",
    "payload = {\"instances\" : tokenized_message}\n",
    "print(payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc90e4b0-203b-4b9d-bbf2-9ebc27071696",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = text_classifier.predict(data=payload)\n",
    "for prediction in predictions:\n",
    "    predicted_class = prediction['label'][0].lstrip('__label__')\n",
    "    print('SPAM' if predicted_class == '1' else 'HAM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b91eb7-b569-4ff1-ab49-ea0cb7eb7781",
   "metadata": {},
   "outputs": [],
   "source": [
    "#text_classifier.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
